var documenterSearchIndex = {"docs":
[{"location":"#RayTracer-:-Differentiable-Ray-Tracing-in-Julia-1","page":"Home","title":"RayTracer : Differentiable Ray Tracing in Julia","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"<p align=\"center\">\n    <video width=\"512\" height=\"320\" autoplay loop>\n        <source src=\"./assets/udem1.webm\" type=\"video/webm\">\n    </video> \n</p>","category":"page"},{"location":"#","page":"Home","title":"Home","text":"RayTracer.jl is a library for differentiable ray tracing. It provides utilities for","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Render complex 3D scenes.\nDifferentiate the Ray Tracer wrt arbitrary scene parameters for Gradient Based Inverse Rendering.","category":"page"},{"location":"#Installation-1","page":"Home","title":"Installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Download Julia 1.0 or later. ","category":"page"},{"location":"#","page":"Home","title":"Home","text":"For the time being, the library is under active development and hence is not registered. But the master branch is pretty stable for experimentation. To install it simply open a julia REPL and  do ] add https://github.com/avik-pal/RayTracer.jl.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The master branch will do all computation on CPU. To try out the experimental GPU support do ] add https://github.com/avik-pal/RayTracer.jl#ap/gpu. To observe the potential performance gains of using GPU you will have to render scenes having more number of objects and the 2D image must be of reasonably high resolution.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"note: Note\nOnly rendering is currently supported on GPUs. Gradient Computation is broken but will be supported in the future.","category":"page"},{"location":"#Supporting-and-Citing-1","page":"Home","title":"Supporting and Citing","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"This software was developed as part of academic research. If you would like to help support it, please star the repository. If you use this software as part of your research, teaching, or other activities, we would be grateful if you could cite:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"@misc{pal2019raytracerjl,\n    title={{RayTracer.jl: A Differentiable Renderer that supports Parameter Optimization for Scene Reconstruction}},\n    author={Avik Pal},\n    year={2019},\n    eprint={1907.07198},\n    archivePrefix={arXiv},\n    primaryClass={cs.GR}\n}","category":"page"},{"location":"#Contribution-Guidelines-1","page":"Home","title":"Contribution Guidelines","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"This package is written and maintained by Avik Pal. Please fork and send a pull request or create a GitHub issue for bug reports. If you are submitting a pull request make sure to follow the official Julia Style Guide and please use 4 spaces and NOT tabs.","category":"page"},{"location":"#Adding-a-new-feature-1","page":"Home","title":"Adding a new feature","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"For adding a new feature open a Github Issue first to discuss about it.\nPlease note that we try and avoid having many primitive objects. This might speed up  rendering in some rare cases (as most objects will end up being represented as Triangles) but is really painful to maintain in the future.\nIf you wish to add rendering algorithms it needs to be added to the src/renderers directory. Ideally we wish that this is differentiable but we do accept algorithms which are not differentiable (simply add a note in the documentation).\nAny new type that is defined should have a corresponding entry in src/gradients/zygote.jl. Look at existing types to understand how it is done. Note that it is a pretty ugly thing to do and becomes uglier as the number of fields in your struct increases, so do not define something that has a lot of fields unless you need it (see Material).\nIf you don't want a field in your custom type to be not updated while inverse rendering create a subtype of RayTracer.FixedParams and wrap those field in it and store it in your custom type.","category":"page"},{"location":"#Adding-a-tutorial/example-1","page":"Home","title":"Adding a tutorial/example","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"We use Literate.jl to convert examples to markdown files. Look into its documentation\nNext use the following commands to convert he script to markdown","category":"page"},{"location":"#","page":"Home","title":"Home","text":"julia> using Literate\n\njulia> Literate.markdown(\"examples/your_example.jl\", \"docs/src/getting_started/\",\n                         documenter = false)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Add an entry to docs/make.jl so that it is available in the side navigation bar.\nAdd an entry to the docs/src/index.md Contents section.","category":"page"},{"location":"#Contents-1","page":"Home","title":"Contents","text":"","category":"section"},{"location":"#Home-1","page":"Home","title":"Home","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Pages = [\n    \"index.md\"\n]\nDepth = 2","category":"page"},{"location":"#Getting-Started-Tutorials-1","page":"Home","title":"Getting Started Tutorials","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Pages = [\n    \"getting_started/teapot_rendering.md\",\n    \"getting_started/inverse_lighting.md\",\n    \"getting_started/optim_compatibility.md\"\n]\nDepth = 2","category":"page"},{"location":"#API-Documentation-1","page":"Home","title":"API Documentation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Pages = [\n    \"api/utilities.md\",\n    \"api/differentiation.md\",\n    \"api/scene.md\",\n    \"api/optimization.md\",\n    \"api/renderers.md\",\n    \"api/accelerators.md\"\n]\nDepth = 2","category":"page"},{"location":"#Index-1","page":"Home","title":"Index","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"","category":"page"},{"location":"getting_started/teapot_rendering/#Introduction-to-rendering-using-RayTracer.jl-1","page":"Introduction to Rendering","title":"Introduction to rendering using RayTracer.jl","text":"","category":"section"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"In this example we will render the famous UTAH Teapot model. We will go through the entire rendering API. We will load an obj file for the scene. This needs to be downloaded manually.","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"Run this code in your terminal to get the file: wget https://raw.githubusercontent.com/McNopper/OpenGL/master/Binaries/teapot.obj","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"If you are using REPL mode you need the ImageView.jl package","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"using RayTracer, Images #, ImageView","category":"page"},{"location":"getting_started/teapot_rendering/#General-Attributes-of-the-Scene-1","page":"Introduction to Rendering","title":"General Attributes of the Scene","text":"","category":"section"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"Specify the dimensions of the image we want to generate. screen_size is never passed into the RayTracer directly so it need not be a named tuple.","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"screen_size = (w = 256, h = 256)","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"Load the teapot object from an obj file. We can also specify the scene using primitive objects directly but that becomes a bit involved when there are complicated objects in the scene.","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"scene = load_obj(\"teapot.obj\")","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"We shall define a convenience function for rendering and saving the images. For understanding the parameters passed to the individual functions look into the documentations of get_primary_rays, raytrace and get_image","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"function generate_render_and_save(cam, light, filename)\n    #src # Get the primary rays for the camera\n    origin, direction = get_primary_rays(cam)\n\n    #src # Render the scene\n    color = raytrace(origin, direction, scene, light, origin, 2)\n\n    #src # This will reshape `color` into the proper dimensions and return\n    #src # an RGB image\n    img = get_image(color, screen_size...)\n\n    #src # Display the image\n    #src # For REPL mode change this to `imshow(img)`\n    display(img)\n\n    #src # Save the generated image\n    save(filename, img)\nend","category":"page"},{"location":"getting_started/teapot_rendering/#Understanding-the-Light-and-Camera-API-1","page":"Introduction to Rendering","title":"Understanding the Light and Camera API","text":"","category":"section"},{"location":"getting_started/teapot_rendering/#DistantLight-1","page":"Introduction to Rendering","title":"DistantLight","text":"","category":"section"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"In this example we will be using the DistantLight. This king of lighting is useful when we want to render a scene in which all parts of the scene receive the same intensity of light.","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"For the DistantLight we need to provide three attributes:","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"Color     - Color of the Light Rays. Must be a Vec3 Object\nIntensity - Intensity of the Light\nDirection - The direction of light rays. Again this needs to be a Vec3 Object","category":"page"},{"location":"getting_started/teapot_rendering/#Camera-1","page":"Introduction to Rendering","title":"Camera","text":"","category":"section"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"We use a perspective view Camera Model in RayTracer. Let us look into the arguments we need to pass into the Camera constructor.","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"LookFrom - The position of the Camera\nLookAt   - The point in 3D space where the Camera is pointing\nvup      - The UP vector of the world (typically Vec3(0.0, 1.0, 0.0), i.e. the y-axis)\nvfov     - Field of View of the Camera\nFocus    - The focal length of the Camera\nWidth    - Width of the output image\nHeight   - Height of the output image","category":"page"},{"location":"getting_started/teapot_rendering/#Rendering-Different-Views-of-the-Teapot-1","page":"Introduction to Rendering","title":"Rendering Different Views of the Teapot","text":"","category":"section"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"Now that we know what each argument means let us render the teapot","category":"page"},{"location":"getting_started/teapot_rendering/#TOP-VIEW-Render-1","page":"Introduction to Rendering","title":"TOP VIEW Render","text":"","category":"section"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"light = DistantLight(\n    Vec3(1.0f0),\n    100.0f0,\n    Vec3(0.0f0, 1.0f0, 0.0f0)\n)\n\ncam = Camera(\n    Vec3(1.0f0, 10.0f0, -1.0f0),\n    Vec3(0.0f0),\n    Vec3(0.0f0, 1.0f0, 0.0f0),\n    45.0f0,\n    1.0f0,\n    screen_size...\n)\n\ngenerate_render_and_save(cam, light, \"teapot_top.jpg\")","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"<p align=\"center\">\n    <img width=256 height=256 src=\"../../assets/teapot_top.jpg\">\n</p>","category":"page"},{"location":"getting_started/teapot_rendering/#SIDE-VIEW-Render-1","page":"Introduction to Rendering","title":"SIDE VIEW Render","text":"","category":"section"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"light = DistantLight(\n    Vec3(1.0f0),\n    100.0f0,\n    Vec3(1.0f0, 1.0f0, -1.0f0)\n)\n\ncam = Camera(\n    Vec3(1.0f0, 2.0f0, -10.0f0),\n    Vec3(0.0f0, 1.0f0, 0.0f0),\n    Vec3(0.0f0, 1.0f0, 0.0f0),\n    45.0f0,\n    1.0f0,\n    screen_size...\n)\n\ngenerate_render_and_save(cam, light, \"teapot_side.jpg\")","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"<p align=\"center\">\n    <img width=256 height=256 src=\"../../assets/teapot_side.jpg\">\n</p>","category":"page"},{"location":"getting_started/teapot_rendering/#FRONT-VIEW-Render-1","page":"Introduction to Rendering","title":"FRONT VIEW Render","text":"","category":"section"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"light = DistantLight(\n    Vec3(1.0f0),\n    100.0f0,\n    Vec3(1.0f0, 1.0f0, 0.0f0)\n)\n\ncam = Camera(\n    Vec3(10.0f0, 2.0f0, 0.0f0),\n    Vec3(0.0f0, 1.0f0, 0.0f0),\n    Vec3(0.0f0, 1.0f0, 0.0f0),\n    45.0f0,\n    1.0f0,\n    screen_size...\n)\n\ngenerate_render_and_save(cam, light, \"teapot_front.jpg\")","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"<p align=\"center\">\n    <img width=256 height=256 src=\"../../assets/teapot_front.jpg\">\n</p>","category":"page"},{"location":"getting_started/teapot_rendering/#Next-Steps-1","page":"Introduction to Rendering","title":"Next Steps","text":"","category":"section"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"Try Rendering complex environments with RayTracer\nLook into the other examples in examples/\nRead about inverse rendering and see the examples on that","category":"page"},{"location":"getting_started/teapot_rendering/#","page":"Introduction to Rendering","title":"Introduction to Rendering","text":"This page was generated using Literate.jl.","category":"page"},{"location":"getting_started/inverse_lighting/#Inverse-Lighting-Tutorial-1","page":"Inverse Lighting","title":"Inverse Lighting Tutorial","text":"","category":"section"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"In this tutorial we shall explore the inverse lighting problem. Here, we shall try to reconstruct a target image by optimizing the parameters of the light source (using gradients).","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"using RayTracer, Images, Zygote, Flux, Statistics","category":"page"},{"location":"getting_started/inverse_lighting/#Configuring-the-Scene-1","page":"Inverse Lighting","title":"Configuring the Scene","text":"","category":"section"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"Reduce the screen_size if the optimization is taking a bit long","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"screen_size = (w = 300, h = 300)","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"Now we shall load the scene using load_obj function. For this we need the obj and mtl files. They can be downloaded using the following commands:","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"wget https://raw.githubusercontent.com/tejank10/Duckietown.jl/master/src/meshes/tree.obj\nwget https://raw.githubusercontent.com/tejank10/Duckietown.jl/master/src/meshes/tree.mtl","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"scene = load_obj(\"./tree.obj\")","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"Let us set up the Camera. For a more detailed understanding of the rendering process look into Introduction to rendering using RayTracer.jl.","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"cam = Camera(\n    lookfrom = Vec3(0.0f0, 6.0f0, -10.0f0),\n    lookat   = Vec3(0.0f0, 2.0f0,  0.0f0),\n    vup      = Vec3(0.0f0, 1.0f0,  0.0f0),\n    vfov     = 45.0f0,\n    focus    = 0.5f0,\n    width    = screen_size.w,\n    height   = screen_size.h\n)\n\norigin, direction = get_primary_rays(cam)","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"We should define a few convenience functions. Since we are going to calculate the gradients only wrt to light we have it as an argument to the function. Having scene as an additional parameters simply allows us to test our method for other meshes without having to run Zygote.refresh() repeatedly.","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"function render(light, scene)\n    packed_image = raytrace(origin, direction, scene, light, origin, 2)\n    array_image = reshape(hcat(packed_image.x, packed_image.y, packed_image.z),\n                          (screen_size.w, screen_size.h, 3, 1))\n    return array_image\nend\n\nshowimg(img) = colorview(RGB, permutedims(img[:,:,:,1], (3,2,1)))","category":"page"},{"location":"getting_started/inverse_lighting/#inv_light-1","page":"Inverse Lighting","title":"Ground Truth Image","text":"","category":"section"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"For this tutorial we shall use the PointLight source. We define the ground truth lighting source and the rendered image. We will later assume that we have no information about this lighting condition and try to reconstruct the image.","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"light_gt = PointLight(\n    color     = Vec3(1.0f0, 1.0f0, 1.0f0),\n    intensity = 20000.0f0,\n    position  = Vec3(1.0f0, 10.0f0, -50.0f0)\n)\n\ntarget_img = render(light_gt, scene)","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"The presence of zeroonenorm is very important here. It rescales the values in the image to 0 to 1. If we don't perform this step Images will clamp the values while generating the image in RGB format.","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"showimg(zeroonenorm(target_img))","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"<p align=\"center\">\n    <img width=300 height=300 src=\"../../assets/inv_light_original.png\">\n</p>","category":"page"},{"location":"getting_started/inverse_lighting/#Initial-Guess-of-Lighting-Parameters-1","page":"Inverse Lighting","title":"Initial Guess of Lighting Parameters","text":"","category":"section"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"We shall make some arbitrary guess of the lighting parameters (intensity and position) and try to get back the image in Ground Truth Image","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"light_guess = PointLight(\n    color     = Vec3(1.0f0, 1.0f0, 1.0f0),\n    intensity = 1.0f0,\n    position  = Vec3(-1.0f0, -10.0f0, -50.0f0)\n)\n\nshowimg(zeroonenorm(render(light_guess, scene)))","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"<p align=\"center\">\n    <img width=300 height=300 src=\"../../assets/inv_light_initial.png\">\n</p>","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"We shall store the images in results_inv_lighting directory","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"mkpath(\"results_inv_lighting\")\n\nsave(\"./results_inv_lighting/inv_light_original.png\",\n     showimg(zeroonenorm(render(light_gt, scene))))\nsave(\"./results_inv_lighting/inv_light_initial.png\",\n     showimg(zeroonenorm(render(light_guess, scene))))","category":"page"},{"location":"getting_started/inverse_lighting/#Optimization-Loop-1","page":"Inverse Lighting","title":"Optimization Loop","text":"","category":"section"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"We will use the ADAM optimizer from Flux. (Try experimenting with other optimizers as well). We can also use frameworks like Optim.jl for optimization. We will show how to do it in a future tutorial","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"for i in 1:401\n    loss, back_fn = Zygote.forward(light_guess) do L\n        sum((render(L, scene) .- target_img) .^ 2)\n    end\n    @show loss\n    gs = back_fn(1.0f0)\n    update!(opt, light_guess.intensity, gs[1].intensity)\n    update!(opt, light_guess.position, gs[1].position)\n    if i % 5 == 1\n        save(\"./results_inv_lighting/iteration_$i.png\",\n             showimg(zeroonenorm(render(light_guess, scene))))\n    end\nend","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"If we generate a gif for the optimization process it will look similar to this","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"<p align=\"center\">\n     <img width=300 height=300 src=\"../../assets/inv_lighting.gif\">\n</p>","category":"page"},{"location":"getting_started/inverse_lighting/#","page":"Inverse Lighting","title":"Inverse Lighting","text":"This page was generated using Literate.jl.","category":"page"},{"location":"getting_started/optim_compatibility/#Optimizing-Scene-Parameters-using-Optim.jl-1","page":"Optimizing using Optim.jl","title":"Optimizing Scene Parameters using Optim.jl","text":"","category":"section"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"In this tutorial we will explore the exact same problem as demonstrated in Inverse Lighting Tutorial but this time we will use the Optimization Package Optim.jl. I would recommend going through a few of the tutorials on Optim before starting this one.","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"If you have already read the previous tutorial, you can safely skip to Writing the Optimization Loop using Optim. The part previous to this is same as the previous tutorial.","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"using RayTracer, Images, Zygote, Flux, Statistics, Optim","category":"page"},{"location":"getting_started/optim_compatibility/#Script-for-setting-up-the-Scene-1","page":"Optimizing using Optim.jl","title":"Script for setting up the Scene","text":"","category":"section"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"screen_size = (w = 64, h = 64)\n\nscene = load_obj(\"./tree.obj\")\n\ncam = Camera(\n    Vec3(0.0f0, 6.0f0, -10.0f0),\n    Vec3(0.0f0, 2.0f0,  0.0f0),\n    Vec3(0.0f0, 1.0f0,  0.0f0),\n    45.0f0,\n    0.5f0,\n    screen_size...\n)\n\norigin, direction = get_primary_rays(cam)\n\nfunction render(light, scene)\n    packed_image = raytrace(origin, direction, scene, light, origin, 2)\n    array_image = reshape(hcat(packed_image.x, packed_image.y, packed_image.z),\n                          (screen_size.w, screen_size.h, 3, 1))\n    return array_image\nend\n\nshowimg(img) = colorview(RGB, permutedims(img[:,:,:,1], (3,2,1)))\n\nlight_gt = PointLight(\n    Vec3(1.0f0, 1.0f0, 1.0f0),\n    20000.0f0,\n    Vec3(1.0f0, 10.0f0, -50.0f0)\n)\n\ntarget_img = render(light_gt, scene)\n\nshowimg(zeroonenorm(render(light_gt, scene)))\n\nlight_guess = PointLight(\n    Vec3(1.0f0, 1.0f0, 1.0f0),\n    1.0f0,\n    Vec3(-1.0f0, -10.0f0, -50.0f0)\n)\n\nshowimg(zeroonenorm(render(light_guess, scene)))","category":"page"},{"location":"getting_started/optim_compatibility/#Writing-the-Optimization-Loop-using-Optim-1","page":"Optimizing using Optim.jl","title":"Writing the Optimization Loop using Optim","text":"","category":"section"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"Since, there is no direct support of Optim (unlike for Flux) in RayTracer the interface might seem a bit ugly. This is mainly due to the way the two optimization packages work. Flux allows inplace operation and ideally even RayTracer prefers that. But Optim requires us to give the parameters as an AbstractArray.","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"Firstly, we shall extract the parameters, using the RayTracer.get_params function, we want to optimize.","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"initial_parameters = RayTracer.get_params(light_guess)[end-3:end]","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"Since the input to the loss_function is an abstract array we need to convert it into a form that the RayTracer understands. For this we shall use the RayTracer.set_params! function which will modify the parameters inplace.","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"In this function we simply compute the loss values and print it for our reference","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"function loss_function(θ::AbstractArray)\n    light_optim = deepcopy(light_guess)\n    RayTracer.set_params!(light_optim.intensity, θ[1:1])\n    RayTracer.set_params!(light_optim.position, θ[2:end])\n    loss = sum((render(light_optim, scene) .- target_img) .^ 2)\n    @show loss\n    return loss\nend","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"RayTracer uses Zygote's Reverse Mode AD for computing the derivatives. However, the default in Optim is ForwardDiff. Hence, we need to override that by giving our own gradient function.","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"function ∇loss_function!(G, θ::AbstractArray)\n    light_optim = deepcopy(light_guess)\n    RayTracer.set_params!(light_optim.intensity, θ[1:1])\n    RayTracer.set_params!(light_optim.position, θ[2:end])\n    gs = gradient(light_optim) do L\n        sum((render(L, scene) .- target_img) .^ 2)\n    end\n    G .= RayTracer.get_params(gs[1])[end-3:end]\nend","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"Now we simply call the optimize function with LBFGS optimizer.","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"res = optimize(loss_function, ∇loss_function!, initial_parameters, LBFGS())\n\n@show res.minimizer","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"It might be interesting to note that convergence using LBFGS was much faster (only 252 iterations) compared to ADAM (401 iterations).","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"If we generate a gif for the optimization process it will look similar to this","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"<p align=\"center\">\n     <img width=300 height=300 src=\"../../assets/inv_lighting_optim.gif\">\n</p>","category":"page"},{"location":"getting_started/optim_compatibility/#","page":"Optimizing using Optim.jl","title":"Optimizing using Optim.jl","text":"This page was generated using Literate.jl.","category":"page"},{"location":"api/utilities/#","page":"General Utilities","title":"General Utilities","text":"CurrentModule = RayTracer","category":"page"},{"location":"api/utilities/#General-Utilities-1","page":"General Utilities","title":"General Utilities","text":"","category":"section"},{"location":"api/utilities/#","page":"General Utilities","title":"General Utilities","text":"List of the General Functions and Types provided by the RayTracer. Most of the other functionalities are built upon these.","category":"page"},{"location":"api/utilities/#","page":"General Utilities","title":"General Utilities","text":"Pages = [\"utilities.md\"]","category":"page"},{"location":"api/utilities/#Documentation-1","page":"General Utilities","title":"Documentation","text":"","category":"section"},{"location":"api/utilities/#","page":"General Utilities","title":"General Utilities","text":"Modules = [RayTracer]\nPages = [\"utils.jl\",\n         \"imutils.jl\"]","category":"page"},{"location":"api/utilities/#RayTracer.Vec3","page":"General Utilities","title":"RayTracer.Vec3","text":"Vec3\n\nThis is the central type for RayTracer. All of the other types are defined building upon this.                                                      \n\nAll the fields of the Vec3 instance contains Arrays. This ensures that we can collect the gradients w.r.t the fields using the Params API of Zygote.\n\nFields:\n\nx\ny\nz\n\nThe types of x, y, and z must match. Also, if scalar input is given to the constructor it will be cnverted into a 1-element Vector.\n\nDefined Operations for Vec3:\n\n+, -, * – These operations will be broadcasted even though there is no explicit                  mention of broadcasting.\ndot\nl2norm\ncross\nclamp\nzero\nsimilar\none\nmaximum\nminimum\nnormalize\nsize\ngetindex – This returns a named tuple\n\n\n\n\n\n","category":"type"},{"location":"api/utilities/#RayTracer.rgb","page":"General Utilities","title":"RayTracer.rgb","text":"rgb is an alias for Vec3. It makes more sense to use this while defining colors. \n\n\n\n\n\n","category":"type"},{"location":"api/utilities/#RayTracer.get_image-Union{Tuple{T}, Tuple{Vec3{T},Any,Any}} where T","page":"General Utilities","title":"RayTracer.get_image","text":"get_image(image, width, height)\n\nReshapes and normalizes a Vec3 color format to the RGB format of Images for easy loading, saving and visualization.\n\nArguments:\n\nimage  - The rendered image in flattened Vec3 format          (i.e., the output of the raytrace, rasterize, etc.)\nwidth  - Width of the output image\nheight - Height of the output image\n\n\n\n\n\n","category":"method"},{"location":"api/utilities/#RayTracer.zeroonenorm-Tuple{Any}","page":"General Utilities","title":"RayTracer.zeroonenorm","text":"zeroonenorm(x::AbstractArray)\n\nNormalizes the elements of the array to values between 0 and 1.\n\nnote: Note\nThis function exists because the version of Zygote we use returns incorrect gradient for 1/maximum(x) function. This has been fixed on the latest release of Zygote.\n\n\n\n\n\n","category":"method"},{"location":"api/utilities/#RayTracer.FixedParams","page":"General Utilities","title":"RayTracer.FixedParams","text":"FixedParams\n\nAny subtype of FixedParams is not optimized using the update! API. For example, we don't want the screen size to be altered while inverse rendering, this is ensured by wrapping those parameters in a subtype of FixedParams.\n\n\n\n\n\n","category":"type"},{"location":"api/utilities/#RayTracer.bigmul-Tuple{Any}","page":"General Utilities","title":"RayTracer.bigmul","text":"bigmul(x)\n\nReturns the output same as typemax. However, in case gradients are computed, it will return the gradient to be 0 instead of nothing as in case of typemax.\n\n\n\n\n\n","category":"method"},{"location":"api/utilities/#RayTracer.camera2world-Tuple{Vec3,Any}","page":"General Utilities","title":"RayTracer.camera2world","text":"camera2world(point::Vec3, cameratoworld::Matrix)\n\nConverts a point in 3D Camera Space to the 3D World Space. To obtain the camera_to_world matrix use the get_transformation_matrix function.\n\n\n\n\n\n","category":"method"},{"location":"api/utilities/#RayTracer.extract-Union{Tuple{T}, Tuple{Any,T}} where T<:Number","page":"General Utilities","title":"RayTracer.extract","text":"extract(cond, x<:Number)\nextract(cond, x<:AbstractArray)\nextract(cond, x::Vec3)\n\nExtracts the elements of x (in case it is an array) for which the indices corresponding to the cond are true.\n\nnote: Note\nextract has a performance penalty when used on GPUs.\n\nExample:\n\njulia> using RayTracer;\n\njulia> a = [1.0, 2.0, 3.0, 4.0]\n4-element Array{Float64,1}:\n 1.0\n 2.0\n 3.0\n 4.0\n\njulia> cond = a .< 2.5\n4-element BitArray{1}:\n 1\n 1\n 0\n 0\n\njulia> RayTracer.extract(cond, a)\n2-element Array{Float64,1}:\n 1.0\n 2.0\n\n\n\n\n\n","category":"method"},{"location":"api/utilities/#RayTracer.place-Tuple{Vec3,Any}","page":"General Utilities","title":"RayTracer.place","text":"place(a::Vec3, cond)\nplace(a::Array, cond, val = 0)\n\nConstructs a new Vec3 or Array depending on the type of a with array length equal to that of cond filled with zeros (or val). Then it fills the positions corresponding to the true values of cond with the values in a.\n\nThe length of each array in a must be equal to the number of true values in the  cond array.\n\nExample:\n\njulia> using RayTracer;\n\njulia> a = Vec3(1, 2, 3)\nx = 1, y = 2, z = 3\n\njulia> cond = [1, 2, 3] .> 2\n3-element BitArray{1}:\n 0\n 0\n 1\n\njulia> RayTracer.place(a, cond)\nVec3 Object\n    Length = 3\n    x = [0, 0, 1]\n    y = [0, 0, 2]\n    z = [0, 0, 3]\n\n\n\n\n\n","category":"method"},{"location":"api/utilities/#RayTracer.place_idx!-Tuple{Vec3,Vec3,Any}","page":"General Utilities","title":"RayTracer.place_idx!","text":"place_idx!(a::Vec3, b::Vec3, idx)\n\nNumber of trues in idx must be equal to the number of elements in b.\n\nThis function involves mutation of arrays. Since the version of Zygote we use does not support mutation we specify a custom adjoint for this function.\n\nArguments:\n\na   - The contents of this Vec3 will be updated\nb   - The contents of b are copied into a\nidx - The indices of a which are updated. This is a BitArray with         length of idx being equal to a.x\n\n\n\n\n\n","category":"method"},{"location":"api/utilities/#RayTracer.world2camera-Tuple{Vec3,Any}","page":"General Utilities","title":"RayTracer.world2camera","text":"world2camera(point::Vec3, world_to_camera::Matrix)\n\nConverts a point in 3D World Space to the 3D Camera Space. To obtain the world_to_camera matrix take the inv of the output from the get_transformation_matrix function.\n\n\n\n\n\n","category":"method"},{"location":"api/utilities/#RayTracer.@diffops-Tuple{Any}","page":"General Utilities","title":"RayTracer.@diffops","text":"@diffops MyType::DataType\n\nGenerates functions for performing gradient based optimizations on this custom type. 5 functions are generated.\n\nx::MyType + y::MyType – For Gradient Accumulation\nx::MyType - y::MyType – For Gradient Based Updates\nx::MyType * η<:Real   – For Multiplication of the Learning Rate with Gradient\nη<:Real * x::MyType   – For Multiplication of the Learning Rate with Gradient\nx::MyType * y::MyType – Just for the sake of completeness.\n\nMost of these functions do not make semantic sense. For example, adding 2 PointLight instances do not make sense but in case both of them are gradients, it makes perfect sense to accumulate them in a third PointLight instance.\n\n\n\n\n\n","category":"macro"},{"location":"api/utilities/#","page":"General Utilities","title":"General Utilities","text":"get_params\nset_params!","category":"page"},{"location":"api/utilities/#RayTracer.get_params","page":"General Utilities","title":"RayTracer.get_params","text":"get_params(x)\n\nGet the parameters from a struct that can be tuned. The output is in the form of an array.\n\nExample:\n\njulia> using RayTracer;\n\njulia> scene = Triangle(Vec3(-1.9f0, 1.6f0, 1.0f0), Vec3(1.0f0, 1.0f0, 0.0f0), Vec3(-0.5f0, -1.0f0, 0.0f0),\n                        Material())\nTriangle Object:\n    Vertex 1 - x = -1.9, y = 1.6, z = 1.0\n    Vertex 2 - x = 1.0, y = 1.0, z = 0.0\n    Vertex 3 - x = -0.5, y = -1.0, z = 0.0\n    Material{Array{Float32,1},Array{Float32,1},Nothing,Nothing,Nothing,Nothing}(x = 1.0, y = 1.0, z = 1.0, x = 1.0, y = 1.0, z = 1.0, x = 1.0, y = 1.0, z = 1.0, Float32[50.0], Float32[0.5], nothing, nothing, nothing, nothing)\n\njulia> RayTracer.get_params(scene)\n20-element Array{Float32,1}:\n -1.9\n  1.6\n  1.0\n  1.0\n  1.0\n  0.0\n -0.5\n -1.0\n  0.0\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n 50.0\n  0.5\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#RayTracer.set_params!","page":"General Utilities","title":"RayTracer.set_params!","text":"set_params!(x, y::AbstractArray)\n\nSets the tunable parameters of the struct x. The index of the last element set into the struct is returned as output. This may be used to confirm that the size of the input array was as expected.\n\nExample:\n\njulia> using RayTracer;\n\njulia> scene = Triangle(Vec3(-1.9f0, 1.6f0, 1.0f0), Vec3(1.0f0, 1.0f0, 0.0f0), Vec3(-0.5f0, -1.0f0, 0.0f0),\n                        Material())\nTriangle Object:\n    Vertex 1 - x = -1.9, y = 1.6, z = 1.0\n    Vertex 2 - x = 1.0, y = 1.0, z = 0.0\n    Vertex 3 - x = -0.5, y = -1.0, z = 0.0\n    Material{Array{Float32,1},Array{Float32,1},Nothing,Nothing,Nothing,Nothing}(x = 1.0, y = 1.0, z = 1.0, x = 1.0, y = 1.0, z = 1.0, x = 1.0, y = 1.0, z = 1.0, Float32[50.0], Float32[0.5], nothing, nothing, nothing, nothing)\n\njulia> new_params = collect(1.0f0:20.0f0)\n20-element Array{Float32,1}:\n  1.0\n  2.0\n  3.0\n  4.0\n  5.0\n  6.0\n  7.0\n  8.0\n  9.0\n 10.0\n 11.0\n 12.0\n 13.0\n 14.0\n 15.0\n 16.0\n 17.0\n 18.0\n 19.0\n 20.0\n\njulia> RayTracer.set_params!(scene, new_params);\n\njulia> scene\nTriangle Object:\n    Vertex 1 - x = 1.0, y = 2.0, z = 3.0\n    Vertex 2 - x = 4.0, y = 5.0, z = 6.0\n    Vertex 3 - x = 7.0, y = 8.0, z = 9.0\n    Material{Array{Float32,1},Array{Float32,1},Nothing,Nothing,Nothing,Nothing}(x = 10.0, y = 11.0, z = 12.0, x = 13.0, y = 14.0, z = 15.0, x = 16.0, y = 17.0, z = 18.0, Float32[19.0], Float32[20.0], nothing, nothing, nothing, nothing)\n\n\n\n\n\n","category":"function"},{"location":"api/differentiation/#","page":"Differentiation","title":"Differentiation","text":"CurrentModule = RayTracer","category":"page"},{"location":"api/differentiation/#Differentiation-1","page":"Differentiation","title":"Differentiation","text":"","category":"section"},{"location":"api/differentiation/#","page":"Differentiation","title":"Differentiation","text":"The recommended mode of differentation is by Automatic Differentiation using Zygote. Refer to the Zygote docs for this. The API listed below is for numerical differentiation and is very restrictive (and unstable) in its current form. It should only be used as a validation for the gradients from Zygote.","category":"page"},{"location":"api/differentiation/#","page":"Differentiation","title":"Differentiation","text":"Pages = [\"differentiation.md\"]","category":"page"},{"location":"api/differentiation/#Documentation-1","page":"Differentiation","title":"Documentation","text":"","category":"section"},{"location":"api/differentiation/#","page":"Differentiation","title":"Differentiation","text":"ngradient\nnumderiv","category":"page"},{"location":"api/differentiation/#RayTracer.ngradient","page":"Differentiation","title":"RayTracer.ngradient","text":"ngradient(f, xs::AbstractArray...)\n\nComputes the numerical gradients of f w.r.t xs. The function f must return a scalar value for this to work. This function is not meant for general usage as the value of the parameter δ has been tuned for this package specifically.\n\nAlso, it should be noted that these gradients are highly unstable and should be used only for confirming the values obtained through other methods. For meaningful results be sure to use Float64 as Float32 is too numerically unstable.\n\n\n\n\n\n","category":"function"},{"location":"api/differentiation/#RayTracer.numderiv","page":"Differentiation","title":"RayTracer.numderiv","text":"numderiv(f, θ)\nnumderiv(f, θ::AbstractArray)\nnumderiv(f, θ::Real)\n\nCompute the numerical derivates wrt one of the scene parameters. The parameter passed cannot be enclosed in an Array, thus making this not a general method for differentiation.\n\nnote: Note\nThis is not a generalized method for getting the gradients. For that please use Zygote. However, this can be used to debug you model, incase you feel the gradients obtained by other methods is sketchy.\n\n\n\n\n\n","category":"function"},{"location":"api/scene/#","page":"Scene Configuration","title":"Scene Configuration","text":"CurrentModule = RayTracer","category":"page"},{"location":"api/scene/#Scene-Configuration-1","page":"Scene Configuration","title":"Scene Configuration","text":"","category":"section"},{"location":"api/scene/#","page":"Scene Configuration","title":"Scene Configuration","text":"This page provides the details about how to configure the parameters of the scene. For a more hands on tutorial see Introduction to rendering using RayTracer.jl.","category":"page"},{"location":"api/scene/#","page":"Scene Configuration","title":"Scene Configuration","text":"Pages = [\"scene.md\"]","category":"page"},{"location":"api/scene/#Camera-1","page":"Scene Configuration","title":"Camera","text":"","category":"section"},{"location":"api/scene/#","page":"Scene Configuration","title":"Scene Configuration","text":"Modules = [RayTracer]\nPages = [\"camera.jl\"]","category":"page"},{"location":"api/scene/#RayTracer.Camera","page":"Scene Configuration","title":"RayTracer.Camera","text":"Camera\n\nThe Perspective View Camera Model\n\nFields:\n\nlookfrom    - Position of the Camera in 3D World Space\nlookat      - Point in the 3D World Space where the Camera is Pointing\nvfov        - Field of View of the Camera\nfocus       - The focal length of the Camera\nfixedparams - An instance of FixedCameraParams\n\nAvailable Constructors:\n\nCamera(;lookfrom = Vec3(0.0f0), lookat = Vec3(0.0f0),          vup = Vec3(0.0f0, 1.0f0, 0.0f0), vfov = 90.0f0,          focus = 1.0f0, width = 128, height = 128)\nCamera(lookfrom::Vec3{T}, lookat::Vec3{T}, vup::Vec3{T}, vfov::R,         focus::R, width::Int, height::Int) where {T<:AbstractArray, R<:Real} \n\n\n\n\n\n","category":"type"},{"location":"api/scene/#RayTracer.get_primary_rays-Tuple{Camera}","page":"Scene Configuration","title":"RayTracer.get_primary_rays","text":"get_primary_rays(c::Camera)\n\nTakes the configuration of the camera and returns the origin and the direction of the primary rays.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.FixedCameraParams","page":"Scene Configuration","title":"RayTracer.FixedCameraParams","text":"FixedCameraParams\n\nThe Parameters of the Camera which should not be updated in inverse rendering are wrapped into this object.\n\nFields:\n\nvup    - Stores the World UP Vector (In most cases this is the Y-Axis Vec3(0.0, 1.0, 0.0))\nwidth  - Width of the image to be rendered\nheight - Height of the image to be rendered\n\n\n\n\n\n","category":"type"},{"location":"api/scene/#RayTracer.compute_screen_coordinates","page":"Scene Configuration","title":"RayTracer.compute_screen_coordinates","text":"compute_screen_coordinates(c::Camera, film_aperture::Tuple,\n                           inch_to_mm::Real = 25.4)\n\nComputes the coordinates of the 4 corners of the screen and returns top, right, bottom, and left.\n\n\n\n\n\n","category":"function"},{"location":"api/scene/#RayTracer.get_transformation_matrix-Union{Tuple{Camera{T}}, Tuple{T}} where T","page":"Scene Configuration","title":"RayTracer.get_transformation_matrix","text":"get_transformation_matrix(c::Camera)\n\nReturns the camera_to_world transformation matrix. This is used for transforming the coordinates of a Point in 3D Camera Space to 3D World Space using the camera2world function.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#Light-1","page":"Scene Configuration","title":"Light","text":"","category":"section"},{"location":"api/scene/#","page":"Scene Configuration","title":"Scene Configuration","text":"Modules = [RayTracer]\nPages = [\"light.jl\"]","category":"page"},{"location":"api/scene/#RayTracer.DistantLight","page":"Scene Configuration","title":"RayTracer.DistantLight","text":"DistantLight\n\nA source of light that is present at infinity as such the rays from it are in a constant direction. The intensity for this light source always remains constant. This is extremely useful when we are trying to render a large scene like a city.\n\nFields:\n\ncolor     - Color of the Light Rays emitted from the Source.\nintensity - Intensity of the Light Source.\ndirection - Direction of the Light Rays emitted by the Source.\n\nAvailable Constructors:\n\nDistantLight(;color = Vec3(1.0f0), intensity::Real = 1.0f0,                direction = Vec3(0.0f0, 1.0f0, 0.0f0))\nDistantLight(color, intensity::Real, direction)\n\n\n\n\n\n","category":"type"},{"location":"api/scene/#RayTracer.PointLight","page":"Scene Configuration","title":"RayTracer.PointLight","text":"PointLight\n\nA source of light which emits light rays from a point in 3D space. The intensity for this light source diminishes as inverse square of the distance from the point.\n\nFields:\n\ncolor     - Color of the Light Rays emitted from the source.\nintensity - Intensity of the Light Source. This decreases as frac1r^2               where r is the distance of the point from the light source.\nposition  - Location of the light source in 3D world space.\n\nAvailable Constructors:\n\nPointLight(;color = Vec3(1.0f0), intensity::Real = 100.0f0, position = Vec3(0.0f0))\nPointLight(color, intensity::Real, position)\n\n\n\n\n\n","category":"type"},{"location":"api/scene/#RayTracer.Light","page":"Scene Configuration","title":"RayTracer.Light","text":"Light\n\nAll objects emitting light should be a subtype of this. To add a custom light source, two only two functions need to be defined.\n\nget_direction(l::MyCustomLightSource, pt::Vec3) - pt is the point receiving the                                                     light from this source\nget_intensity(l::MyCustomLightSource, pt::Vec3, dist::Array) - dist is the array                                                                  representing the distance                                                                  of the point from the light                                                                  source\n\n\n\n\n\n","category":"type"},{"location":"api/scene/#RayTracer.get_direction-Tuple{RayTracer.Light,Vec3}","page":"Scene Configuration","title":"RayTracer.get_direction","text":"get_direction(l::Light, pt::Vec3)\n\nReturns the direction of light incident from the light source to pt.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.get_intensity-Tuple{RayTracer.Light,Vec3,AbstractArray}","page":"Scene Configuration","title":"RayTracer.get_intensity","text":"get_intensity(l::Light, pt::Vec3, dist::Array)\n\nComputed the intensity of the light ray incident at pt.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.get_shading_info-Tuple{RayTracer.Light,Vec3}","page":"Scene Configuration","title":"RayTracer.get_shading_info","text":"get_shading_info(l::Light, pt::Vec3)\n\nReturns the direction of light incident from the light source onto that Point and the intensity of that light ray. It computes these by internally calling the get_direction and get_intensity functions and hence this function never has to be modified for any Light subtype.\n\nArguments:\n\nl  - The Object of the Light subtype\npt - The Point in 3D Space for which the shading information is queried\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#Materials-1","page":"Scene Configuration","title":"Materials","text":"","category":"section"},{"location":"api/scene/#","page":"Scene Configuration","title":"Scene Configuration","text":"Modules = [RayTracer]\nPages = [\"materials.jl\"]","category":"page"},{"location":"api/scene/#RayTracer.Material","page":"Scene Configuration","title":"RayTracer.Material","text":"Material\n\nThis Type stores information about the material of an Object. We compute the color of a point by dispatching on the type of the material. That is why we store nothing when a particular field is absent.\n\nnote: Note\ntexture_* and uv_coordinates fields are applicable only if the object used is a Triangle. If any of the texture fields are present, uv_coordinates must be present.\n\nFields:\n\ncolor_ambient     - The Ambient Color of the Material.\ncolor_diffuse     - The Diffuse Color of the Material.\ncolor_specular    - The Specular Color of the Material.\nspecular_exponent - Specular Exponent of the Material.\nreflection        - The reflection coefficient of the material.\ntexture_ambient   - Stores the ambient texture image (if present) in Vec3 format.\ntexture_diffuse   - Stores the diffuse texture image (if present) in Vec3 format.\ntexture_specular  - Stores the specular texture image (if present) in VEc3 format.\nuv_coordinates    - The uv coordinates are stored as a vector (of length 3) of tuples.\n\nAvailable Constructors\n\nMaterial(;color_ambient = Vec3(1.0f0), color_diffuse = Vec3(1.0f0),\n          color_specular = Vec3(1.0f0), specular_exponent::Real = 50.0f0,\n          reflection::Real = 0.5f0, texture_ambient = nothing, \n          texture_diffuse = nothing, texture_specular = nothing,\n          uv_coordinates = nothing)\n\n\n\n\n\n","category":"type"},{"location":"api/scene/#RayTracer.get_color-Union{Tuple{S}, Tuple{W}, Tuple{V}, Tuple{R}, Tuple{T}, Tuple{Material{T,R,Nothing,V,W,S},Vec3,Val{:ambient},Any}} where S<:Union{Nothing, Array{T,1} where T} where W<:Union{Nothing, Vec3} where V<:Union{Nothing, Vec3} where R<:(AbstractArray{T,1} where T) where T<:AbstractArray","page":"Scene Configuration","title":"RayTracer.get_color","text":"get_color(m::Material, pt::Vec3, ::Val{T}, obj::Object)\n\nReturns the color at the point pt. We use T and the type of the Material m for efficiently dispatching to the right function. The right function is determined by the presence/absence of the texture field. The possible values of T are :ambient, :diffuse, and :specular.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.reflection-Tuple{Material}","page":"Scene Configuration","title":"RayTracer.reflection","text":"reflection(m::Material)\n\nReturns the reflection coefficient of the Material m.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.specular_exponent-Tuple{Material}","page":"Scene Configuration","title":"RayTracer.specular_exponent","text":"specular_exponent(m::Material)\n\nReturns the specular_exponent of the Material m.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#Objects-1","page":"Scene Configuration","title":"Objects","text":"","category":"section"},{"location":"api/scene/#","page":"Scene Configuration","title":"Scene Configuration","text":"Modules = [RayTracer]\nPages = [\"sphere.jl\",\n         \"triangle.jl\",\n         \"obj_parser.jl\",\n         \"polygon_mesh.jl\",\n         \"objects.jl\"]","category":"page"},{"location":"api/scene/#RayTracer.Sphere","page":"Scene Configuration","title":"RayTracer.Sphere","text":"Sphere\n\nSphere is a primitive object.\n\nFields:\n\ncenter   - Center of the Sphere in 3D world space\nradius   - Radius of the Sphere\nmaterial - Material of the Sphere\n\n\n\n\n\n","category":"type"},{"location":"api/scene/#RayTracer.Triangle","page":"Scene Configuration","title":"RayTracer.Triangle","text":"Triangle\n\nTriangle is a primitive object. Any complex object can be represented as a mesh of Triangles.\n\nFields:\n\nv1       - Vertex 1\nv2       - Vertex 2\nv3       - Vertex 3\nmaterial - Material of the Triangle\n\n\n\n\n\n","category":"type"},{"location":"api/scene/#RayTracer.load_obj-Tuple{Any}","page":"Scene Configuration","title":"RayTracer.load_obj","text":"load_obj(file; outtype = Float32)\n\nParser for obj file. It returns a set of Triangles that make up the scene.\n\nOnly the following things are parsed as of now: v, vt, vn, f, usemtl and mtllib.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.parse_mtllib!-Tuple{Any,Any,Any}","page":"Scene Configuration","title":"RayTracer.parse_mtllib!","text":"parse_mtllib!(file, material_map, outtype)\n\nParses .mtl file and creates a map from the material name to  Material objects.\n\nNot all fields of the mtl file are parsed. We only parse : newmtl, Ka, Kd, Ks, Ns, d, Tr, map_Kd, map_Ks, and map_Ka.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.triangulate_faces-Tuple{Array{T,1} where T,Array{T,1} where T,Array{T,1} where T,Dict}","page":"Scene Configuration","title":"RayTracer.triangulate_faces","text":"triangulate_faces(vertices::Vector, texture_coordinates::Vector,\n                  faces::Vector, material_map::Dict)\n\nTriangulates the faces and converts it into valid Triangle objects.\n\nwarning: Warning\nAvoid using this function in itself. It is designed to be used internally by the load_obj function.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.Object","page":"Scene Configuration","title":"RayTracer.Object","text":"Object\n\nAll primitive objects must be a subtype of this. Currently there are two primitive objects present, Triangle and Sphere. To add support for custom primitive type, two functions need to be defined - intersect and get_normal.\n\n\n\n\n\n","category":"type"},{"location":"api/scene/#Base.intersect-Tuple{RayTracer.Object,Any,Any}","page":"Scene Configuration","title":"Base.intersect","text":"intersect(obj::Object, origin, direction)\n\nComputes the intersection of the light ray with the object. This function returns the t value where intersection_point = origin + t times direction. In case the ray does not intersect with the object Inf is returned.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.get_color-Tuple{RayTracer.Object,Vec3,Val}","page":"Scene Configuration","title":"RayTracer.get_color","text":"get_color(obj::Object, pt::Vec3, sym::Val)\n\nComputes the color at the point pt of the Object obj by dispatching to the correct get_color(obj.material, pt, sym, obj) method.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.get_normal-Tuple{RayTracer.Object,Any,Any}","page":"Scene Configuration","title":"RayTracer.get_normal","text":"get_normal(obj::Object, pt, direction)\n\nReturns the normal at the Point pt of the Object obj. \n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.reflection-Tuple{RayTracer.Object}","page":"Scene Configuration","title":"RayTracer.reflection","text":"reflection(obj::Object)\n\nReturns the reflection coefficient of the material of the Object.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#RayTracer.specular_exponent-Tuple{RayTracer.Object}","page":"Scene Configuration","title":"RayTracer.specular_exponent","text":"specular_exponent(obj::Object)\n\nReturns the specular_exponent of the material of the Object.\n\n\n\n\n\n","category":"method"},{"location":"api/scene/#","page":"Scene Configuration","title":"Scene Configuration","text":"","category":"page"},{"location":"api/renderers/#","page":"Renderers","title":"Renderers","text":"CurrentModule = RayTracer","category":"page"},{"location":"api/renderers/#Renderers-1","page":"Renderers","title":"Renderers","text":"","category":"section"},{"location":"api/renderers/#","page":"Renderers","title":"Renderers","text":"This section describes the renderers available in RayTracer.jl","category":"page"},{"location":"api/renderers/#","page":"Renderers","title":"Renderers","text":"Pages = [\"renderers.md\"]","category":"page"},{"location":"api/renderers/#Documentation-1","page":"Renderers","title":"Documentation","text":"","category":"section"},{"location":"api/renderers/#","page":"Renderers","title":"Renderers","text":"Modules = [RayTracer]\nPages = [\"blinnphong.jl\",\n         \"rasterizer.jl\",\n         \"accelerated_raytracer.jl\"]","category":"page"},{"location":"api/renderers/#RayTracer.raytrace-Tuple{}","page":"Renderers","title":"RayTracer.raytrace","text":"raytrace(origin::Vec3, direction::Vec3, scene::Vector, lgt::Light,\n         eye_pos::Vec3, bounce::Int)\nraytrace(origin::Vec3, direction::Vec3, scene, lgt::Vector{Light},\n         eye_pos::Vec3, bounce::Int)\nraytrace(origin::Vec3, direction::Vec3, scene::BoundingVolumeHierarchy,\n         lgt::Light, eye_pos::Vec3, bounce::Int)\nraytrace(;origin = nothing, direction = nothing, scene = nothing,\n          light_source = nothing, global_illumination = false)\n\nComputes the color contribution to every pixel by tracing every single ray. Internally it calls the light function which implements Blinn Phong Rendering and adds up the color contribution for each object.\n\nThe eye_pos is simply the origin when called by the user. However, the origin keeps changing across the recursive calls to this function and hence it is necessary to keep track of the eye_pos separately.\n\nThe bounce parameter allows the configuration of global illumination. To turn off global illumination set the bounce parameter to >= 2. As expected rendering is much faster if global illumination is off but at the same time is much less photorealistic.\n\nnote: Note\nThe support for multiple lights is primitive as we loop over the lights. Even though it is done in a parallel fashion, it is not the best way to do so. Nevertheless it exists just for the sake of experimentation.\n\nnote: Note\nNone of the parameters (except global_illumination) in the keyword argument version of raytrace is optional. It is just present for convenience.\n\n\n\n\n\n","category":"method"},{"location":"api/renderers/#RayTracer.rasterize-Tuple{Camera,Array{T,1} where T}","page":"Renderers","title":"RayTracer.rasterize","text":"rasterize(cam::Camera, scene::Vector)    rasterize(cam::Camera, scene::Vector, cameratoworld,              worldtocamera, top, right, bottom, left)\n\nImplements the raterization algorithm. This is extremely fast when compared to the raytrace function. However, the image generated is much less photorealistic with no lighting effects.\n\n\n\n\n\n","category":"method"},{"location":"api/renderers/#RayTracer.fseelight-Tuple{Any,Any}","page":"Renderers","title":"RayTracer.fseelight","text":"fseelight(n::Int, light_distances)\n\nChecks if the n^th object in the scene list can see the light source.\n\n\n\n\n\n","category":"method"},{"location":"api/renderers/#RayTracer.light-Tuple{RayTracer.Object,Any,Any,Any,RayTracer.Light,Any,Any,Any,Any}","page":"Renderers","title":"RayTracer.light","text":"light(s::Object, origin, direction, dist, lgt::Light, eye_pos, scene, obj_num, bounce)\n\nImplements the Blinn Phong rendering algorithm. This function is merely for internal usage and should in no case be called by the user. This function is quite general and supports user defined Objects. For support of custom Objects have a look at the examples.\n\nwarning: Warning\nDon't try to use this function by itself. But if you are a person who likes to ignore warnings look into the way raytrace calls this.\n\n\n\n\n\n","category":"method"},{"location":"api/renderers/#RayTracer.reducehcat-Tuple{Any}","page":"Renderers","title":"RayTracer.reducehcat","text":"reducehcat(x)\n\nThis is simply reduce(hcat(x)). The version of Zygote we are currently using can't differentiate through this function. So we define a custom adjoint for this.\n\n\n\n\n\n","category":"method"},{"location":"api/renderers/#RayTracer.convert2raster-Tuple{Vec3,Any,Real,Real,Real,Real,Int64,Int64}","page":"Renderers","title":"RayTracer.convert2raster","text":"convert2raster(vertex_world::Vec3, world_to_camera, left::Real, right::Real,\n               top::Real, bottom::Real, width::Int, height::Int)\nconvert2raster(vertex_camera::Vec3{T}, left::Real, right::Real, top::Real, bottom::Real,\n               width::Int, height::Int) where {T}\n\nConverts a Point in 3D world space to the 3D raster space. The conversion is done by the following steps:\n\nV_camera = World2CameraTransform(V_world)\n\nV_screen_x = -fracV_camera_xV_camera_z\n\nV_screen_y = -fracV_camera_yV_camera_z\n\nV_NDC_x = frac2 times V_screen_x - right - leftright - left\n\nV_NDC_y = frac2 times V_screen_y - top - bottomtop - bottom\n\nV_raster_x = fracV_NDC_x + 12 times width\n\nV_raster_y = frac1 - V_NDC_y2 times height\n\nV_raster_z = - V_camera_z\n\n\n\n\n\n","category":"method"},{"location":"api/renderers/#RayTracer.edge_function-Tuple{Vec3,Vec3,Vec3}","page":"Renderers","title":"RayTracer.edge_function","text":"edge_function(pt1::Vec3, pt2::Vec3, point::Vec3)\n\nChecks on which side of the line formed by pt1 and pt2 does point lie.\n\n\n\n\n\n","category":"method"},{"location":"api/renderers/#RayTracer.edge_function_vector-Tuple{Vec3,Vec3,Vec3}","page":"Renderers","title":"RayTracer.edge_function_vector","text":"edge_function_vector(pt1::Vec3, pt2::Vec3, point::Vec3)\n\nVectoried form of the edge_function\n\n\n\n\n\n","category":"method"},{"location":"api/optimization/#","page":"Optimization","title":"Optimization","text":"CurrentModule = RayTracer","category":"page"},{"location":"api/optimization/#Optimization-1","page":"Optimization","title":"Optimization","text":"","category":"section"},{"location":"api/optimization/#","page":"Optimization","title":"Optimization","text":"One of the primary use cases of RayTracer.jl is to solve the Inverse Rendering Problem. In this problem, we try to predict the 3D scene given a 2D image of it. Since, \"truly\" solving this problem is very difficult, we focus on a subproblem where we assume that we have partial knowledge of the 3D scene and now using this image we need to figure out the correct remaining parameters. We do this by iteratively optimizing the parameters using the gradients obtained with the Differentiation API.","category":"page"},{"location":"api/optimization/#","page":"Optimization","title":"Optimization","text":"We describe the current API for optimizing these parameters below.","category":"page"},{"location":"api/optimization/#","page":"Optimization","title":"Optimization","text":"Pages = [\"api/optimization.md\"]","category":"page"},{"location":"api/optimization/#Documentation-1","page":"Optimization","title":"Documentation","text":"","category":"section"},{"location":"api/optimization/#","page":"Optimization","title":"Optimization","text":"Modules = [RayTracer]\nPages = [\"optimize.jl\"]","category":"page"},{"location":"api/optimization/#RayTracer.update!-Tuple{Any,AbstractArray,AbstractArray}","page":"Optimization","title":"RayTracer.update!","text":"update!(opt, x, Δ)\n\nProvides an interface to use all of the Optimizers provided by Flux. The type of x can be anything as long as the operations defined by @diffops are available for it. By default all the differentiable types inside the Package can be used with it.\n\nThe type of Δ must be same as that of x. This prevent silent type conversion of x which can significantly slow doen the raytracer.\n\nExample:\n\njulia> opt = ADAM()\n\njulia> gs = gradient(loss_function, θ)\n\njulia> update!(opt, θ, gs[1])\n\n\n\n\n\n","category":"method"},{"location":"api/accelerators/#","page":"Acceleration Structures","title":"Acceleration Structures","text":"CurrentModule = RayTracer","category":"page"},{"location":"api/accelerators/#Acceleration-Structures-1","page":"Acceleration Structures","title":"Acceleration Structures","text":"","category":"section"},{"location":"api/accelerators/#","page":"Acceleration Structures","title":"Acceleration Structures","text":"warning: Warning\nThis is a Beta Feature and not all things work with this.","category":"page"},{"location":"api/accelerators/#","page":"Acceleration Structures","title":"Acceleration Structures","text":"Pages = [\"accelerators.md\"]","category":"page"},{"location":"api/accelerators/#Bounding-Volume-Hierarchy-1","page":"Acceleration Structures","title":"Bounding Volume Hierarchy","text":"","category":"section"},{"location":"api/accelerators/#","page":"Acceleration Structures","title":"Acceleration Structures","text":"Bounding Volume Hierarchy (or BVH) acts like a primitive object, just like Triangle or Sphere. So we can simply pass a BVH object into raytrace function.","category":"page"},{"location":"api/accelerators/#","page":"Acceleration Structures","title":"Acceleration Structures","text":"warning: Warning\nThe backward pass for BVH is currently broken","category":"page"},{"location":"api/accelerators/#","page":"Acceleration Structures","title":"Acceleration Structures","text":"Modules = [RayTracer]\nPages = [\"bvh.jl\"]","category":"page"},{"location":"api/accelerators/#RayTracer.BoundingVolumeHierarchy","page":"Acceleration Structures","title":"RayTracer.BoundingVolumeHierarchy","text":"BoundingVolumeHierarchy\n\nAn AccelerationStructure which constructs bounding boxes around groups of triangles to speed up intersection checking. A detailed description of ths technique is present here.\n\nFields:\n\nscene_list - The scene list passed into the BVH constructor but in                sorted order\nroot_node  - Root BVHNode\n\nConstructors:\n\nBoundingVolumeHierarchy(scene::Vector)\n\n\n\n\n\n","category":"type"},{"location":"api/accelerators/#RayTracer.AccelerationStructure","page":"Acceleration Structures","title":"RayTracer.AccelerationStructure","text":"AccelerationStructure\n\nBase Type for all Acceleration Structures. These can be used to speed up rendering by a significant amount. The main design behind an acceleration structure should be such that it can be used as a simple replacement for a vector of Objects.\n\n\n\n\n\n","category":"type"},{"location":"api/accelerators/#RayTracer.BVHNode","page":"Acceleration Structures","title":"RayTracer.BVHNode","text":"BVHNode\n\nA node in the graph created from the scene list using BoundingVolumeHierarchy.\n\nFields:\n\nx_min       - Minimum x-value for the bounding box\nx_max       - Maximum x-value for the bounding box\ny_min       - Minimum y-value for the bounding box \ny_max       - Maximum y-value for the bounding box \nz_min       - Minimum z-value for the bounding box \nz_max       - Maximum z-value for the bounding box \nindex_start - Starting triangle in the scene list\nindex_end   - Last triangle in the scene list\nleft_child  - Can be nothing or another BVHNode\nright_child - Can be nothing or another BVHNode\n\n\n\n\n\n","category":"type"}]
}
